{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data-preprocessing/csv/ohlcv_with_future_tan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_c_30min = df['close_c_30min'].copy()\n",
    "df = df.drop(columns=['close_c_30min'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_np = df.values\n",
    "answer_np = close_c_30min.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = list(), list()\n",
    "\n",
    "for i in range(60, features_np.shape[0]):\n",
    "    X.append(features_np[i-60:i])\n",
    "    y.append(answer_np[i])\n",
    "    \n",
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143877, 60, 14), (143877,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "n_layer_lstm = 3\n",
    "lstm_unit = 8\n",
    "n_layer_dense = 3\n",
    "dense_unit = 16\n",
    "dense_dropout = 0.3\n",
    "lstm_dropout = 0.2\n",
    "act_fn = 'relu'\n",
    "\n",
    "def get_model(n_layer_lstm, lstm_unit, n_layer_dense, dense_unit, dense_dropout, lstm_dropout, act_fn, lr):\n",
    "    inp = Input(shape=(60,14))\n",
    "    for i in range(n_layer_lstm):\n",
    "        if i == n_layer_lstm-1 and i != 0:\n",
    "            x = LSTM(lstm_unit, dropout=lstm_dropout)(x)\n",
    "        elif i == n_layer_lstm-1 and i == 0:\n",
    "            x = LSTM(lstm_unit, dropout=lstm_dropout)(inp)\n",
    "        elif i == 0:\n",
    "            x = LSTM(lstm_unit, return_sequences=True, dropout=lstm_dropout)(inp)\n",
    "        else:\n",
    "            x = LSTM(lstm_unit, return_sequences=True, dropout=lstm_dropout)(x)\n",
    "    for i in range(n_layer_dense):\n",
    "        x = Dense(dense_unit)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(act_fn)(x)\n",
    "        x = Dropout(dense_dropout)(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inp, out)\n",
    "    model.compile(optimizers=Adam(lr), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>> 1 LSTM layers with 32 units and 0 layer of DNN <<<<<<<<<<<<<<<<<<<<\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 60, 14)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                6016      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,049\n",
      "Trainable params: 6,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 115101 samples, validate on 28776 samples\n",
      "Epoch 1/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6887 - accuracy: 0.5347\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55362, saving model to best_params_1_layer_32_units_0_dense\n",
      "WARNING:tensorflow:From C:\\Users\\TaiT_\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_32_units_0_dense\\assets\n",
      "115101/115101 [==============================] - 44s 380us/sample - loss: 0.6887 - accuracy: 0.5348 - val_loss: 0.6835 - val_accuracy: 0.5536\n",
      "Epoch 2/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6858 - accuracy: 0.5471\n",
      "Epoch 00002: val_accuracy did not improve from 0.55362\n",
      "115101/115101 [==============================] - 37s 321us/sample - loss: 0.6858 - accuracy: 0.5471 - val_loss: 0.6878 - val_accuracy: 0.5396\n",
      "Epoch 3/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6852 - accuracy: 0.5511 ETA: \n",
      "Epoch 00003: val_accuracy improved from 0.55362 to 0.56019, saving model to best_params_1_layer_32_units_0_dense\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_32_units_0_dense\\assets\n",
      "115101/115101 [==============================] - 46s 400us/sample - loss: 0.6852 - accuracy: 0.5510 - val_loss: 0.6846 - val_accuracy: 0.5602\n",
      "Epoch 4/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6847 - accuracy: 0.5520\n",
      "Epoch 00004: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 39s 343us/sample - loss: 0.6847 - accuracy: 0.5521 - val_loss: 0.6826 - val_accuracy: 0.5568\n",
      "Epoch 5/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6841 - accuracy: 0.5521\n",
      "Epoch 00005: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 41s 359us/sample - loss: 0.6841 - accuracy: 0.5522 - val_loss: 0.6827 - val_accuracy: 0.5564\n",
      "Epoch 6/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6835 - accuracy: 0.5548\n",
      "Epoch 00006: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 42s 366us/sample - loss: 0.6835 - accuracy: 0.5547 - val_loss: 0.6854 - val_accuracy: 0.5544\n",
      "Epoch 7/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6823 - accuracy: 0.5579 ETA: 0s - loss: 0.682\n",
      "Epoch 00007: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 43s 377us/sample - loss: 0.6823 - accuracy: 0.5578 - val_loss: 0.6854 - val_accuracy: 0.5395\n",
      "Epoch 8/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6814 - accuracy: 0.5607\n",
      "Epoch 00008: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 45s 389us/sample - loss: 0.6814 - accuracy: 0.5608 - val_loss: 0.6842 - val_accuracy: 0.5538\n",
      "Epoch 9/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6808 - accuracy: 0.5614\n",
      "Epoch 00009: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 47s 405us/sample - loss: 0.6808 - accuracy: 0.5614 - val_loss: 0.6843 - val_accuracy: 0.5509\n",
      "Epoch 10/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6790 - accuracy: 0.5656\n",
      "Epoch 00010: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 48s 418us/sample - loss: 0.6789 - accuracy: 0.5656 - val_loss: 0.6880 - val_accuracy: 0.5454\n",
      "Epoch 11/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6780 - accuracy: 0.5687\n",
      "Epoch 00011: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 49s 428us/sample - loss: 0.6780 - accuracy: 0.5687 - val_loss: 0.6898 - val_accuracy: 0.5445\n",
      "Epoch 12/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6770 - accuracy: 0.5701\n",
      "Epoch 00012: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 49s 427us/sample - loss: 0.6770 - accuracy: 0.5701 - val_loss: 0.6869 - val_accuracy: 0.5505\n",
      "Epoch 13/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6754 - accuracy: 0.5740\n",
      "Epoch 00013: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 49s 427us/sample - loss: 0.6754 - accuracy: 0.5739 - val_loss: 0.6888 - val_accuracy: 0.5424\n",
      "Epoch 14/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6738 - accuracy: 0.5765\n",
      "Epoch 00014: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 48s 414us/sample - loss: 0.6738 - accuracy: 0.5765 - val_loss: 0.6867 - val_accuracy: 0.5585\n",
      "Epoch 15/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6721 - accuracy: 0.5806 ETA: 1s -\n",
      "Epoch 00015: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 45s 392us/sample - loss: 0.6721 - accuracy: 0.5807 - val_loss: 0.6909 - val_accuracy: 0.5477\n",
      "Epoch 16/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6702 - accuracy: 0.5840\n",
      "Epoch 00016: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 47s 409us/sample - loss: 0.6702 - accuracy: 0.5840 - val_loss: 0.6911 - val_accuracy: 0.5443\n",
      "Epoch 17/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6681 - accuracy: 0.5865\n",
      "Epoch 00017: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 47s 407us/sample - loss: 0.6681 - accuracy: 0.5866 - val_loss: 0.6953 - val_accuracy: 0.5389\n",
      "Epoch 18/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6663 - accuracy: 0.5922\n",
      "Epoch 00018: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 47s 410us/sample - loss: 0.6663 - accuracy: 0.5921 - val_loss: 0.6961 - val_accuracy: 0.5408\n",
      "Epoch 19/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6640 - accuracy: 0.5943\n",
      "Epoch 00019: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 47s 411us/sample - loss: 0.6640 - accuracy: 0.5943 - val_loss: 0.7009 - val_accuracy: 0.5395\n",
      "Epoch 20/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6619 - accuracy: 0.5986 ETA: 3s - loss: - E\n",
      "Epoch 00020: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 44s 382us/sample - loss: 0.6618 - accuracy: 0.5986 - val_loss: 0.7251 - val_accuracy: 0.5282\n",
      "Epoch 21/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6596 - accuracy: 0.6003\n",
      "Epoch 00021: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 44s 380us/sample - loss: 0.6596 - accuracy: 0.6003 - val_loss: 0.7056 - val_accuracy: 0.5415\n",
      "Epoch 22/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6574 - accuracy: 0.6058\n",
      "Epoch 00022: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 45s 389us/sample - loss: 0.6574 - accuracy: 0.6058 - val_loss: 0.7011 - val_accuracy: 0.5375\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6551 - accuracy: 0.6076\n",
      "Epoch 00023: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 46s 401us/sample - loss: 0.6551 - accuracy: 0.6075 - val_loss: 0.7121 - val_accuracy: 0.5372\n",
      "Epoch 24/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6527 - accuracy: 0.6112\n",
      "Epoch 00024: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 48s 414us/sample - loss: 0.6527 - accuracy: 0.6112 - val_loss: 0.7226 - val_accuracy: 0.5412\n",
      "Epoch 25/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6501 - accuracy: 0.6149\n",
      "Epoch 00025: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 48s 417us/sample - loss: 0.6501 - accuracy: 0.6149 - val_loss: 0.7426 - val_accuracy: 0.5309\n",
      "Epoch 26/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6476 - accuracy: 0.6188\n",
      "Epoch 00026: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 45s 390us/sample - loss: 0.6477 - accuracy: 0.6188 - val_loss: 0.7268 - val_accuracy: 0.5322\n",
      "Epoch 27/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6459 - accuracy: 0.6206 ETA: 1s - loss: 0\n",
      "Epoch 00027: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 45s 395us/sample - loss: 0.6459 - accuracy: 0.6207 - val_loss: 0.7196 - val_accuracy: 0.5335\n",
      "Epoch 28/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6430 - accuracy: 0.6261\n",
      "Epoch 00028: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 47s 405us/sample - loss: 0.6430 - accuracy: 0.6261 - val_loss: 0.7470 - val_accuracy: 0.5379\n",
      "Epoch 29/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6404 - accuracy: 0.6282\n",
      "Epoch 00029: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 46s 402us/sample - loss: 0.6404 - accuracy: 0.6282 - val_loss: 0.7375 - val_accuracy: 0.5449\n",
      "Epoch 30/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6384 - accuracy: 0.6315\n",
      "Epoch 00030: val_accuracy did not improve from 0.56019\n",
      "115101/115101 [==============================] - 47s 405us/sample - loss: 0.6384 - accuracy: 0.6315 - val_loss: 0.7571 - val_accuracy: 0.5299\n",
      ">>>>>>>>>>>>>>>>>>>> 1 LSTM layers with 32 units and 1 layer of DNN <<<<<<<<<<<<<<<<<<<<\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 60, 14)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                6016      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 7,233\n",
      "Trainable params: 7,169\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Train on 115101 samples, validate on 28776 samples\n",
      "Epoch 1/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6877 - accuracy: 0.5462\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50209, saving model to best_params_1_layer_32_units_1_dense\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_32_units_1_dense\\assets\n",
      "115101/115101 [==============================] - 60s 524us/sample - loss: 0.6877 - accuracy: 0.5463 - val_loss: 0.7020 - val_accuracy: 0.5021\n",
      "Epoch 2/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6841 - accuracy: 0.5558\n",
      "Epoch 00002: val_accuracy improved from 0.50209 to 0.52099, saving model to best_params_1_layer_32_units_1_dense\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_32_units_1_dense\\assets\n",
      "115101/115101 [==============================] - 56s 483us/sample - loss: 0.6841 - accuracy: 0.5558 - val_loss: 0.7009 - val_accuracy: 0.5210\n",
      "Epoch 3/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6835 - accuracy: 0.5559\n",
      "Epoch 00003: val_accuracy improved from 0.52099 to 0.53479, saving model to best_params_1_layer_32_units_1_dense\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_32_units_1_dense\\assets\n",
      "115101/115101 [==============================] - 53s 456us/sample - loss: 0.6834 - accuracy: 0.5559 - val_loss: 0.6947 - val_accuracy: 0.5348\n",
      "Epoch 4/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6827 - accuracy: 0.5592\n",
      "Epoch 00004: val_accuracy did not improve from 0.53479\n",
      "115101/115101 [==============================] - 44s 385us/sample - loss: 0.6828 - accuracy: 0.5589 - val_loss: 0.6994 - val_accuracy: 0.5083\n",
      "Epoch 5/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6821 - accuracy: 0.5593\n",
      "Epoch 00005: val_accuracy improved from 0.53479 to 0.54584, saving model to best_params_1_layer_32_units_1_dense\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_32_units_1_dense\\assets\n",
      "115101/115101 [==============================] - 55s 481us/sample - loss: 0.6821 - accuracy: 0.5592 - val_loss: 0.6885 - val_accuracy: 0.5458\n",
      "Epoch 6/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6815 - accuracy: 0.5600\n",
      "Epoch 00006: val_accuracy did not improve from 0.54584\n",
      "115101/115101 [==============================] - 48s 413us/sample - loss: 0.6815 - accuracy: 0.5600 - val_loss: 0.6988 - val_accuracy: 0.5205\n",
      "Epoch 7/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6805 - accuracy: 0.5631\n",
      "Epoch 00007: val_accuracy did not improve from 0.54584\n",
      "115101/115101 [==============================] - 44s 387us/sample - loss: 0.6805 - accuracy: 0.5631 - val_loss: 0.6882 - val_accuracy: 0.5457\n",
      "Epoch 8/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6797 - accuracy: 0.5637\n",
      "Epoch 00008: val_accuracy did not improve from 0.54584\n",
      "115101/115101 [==============================] - 45s 387us/sample - loss: 0.6797 - accuracy: 0.5638 - val_loss: 0.6979 - val_accuracy: 0.5258\n",
      "Epoch 9/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6786 - accuracy: 0.5672\n",
      "Epoch 00009: val_accuracy did not improve from 0.54584\n",
      "115101/115101 [==============================] - 46s 402us/sample - loss: 0.6786 - accuracy: 0.5672 - val_loss: 0.6924 - val_accuracy: 0.5427\n",
      "Epoch 10/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6778 - accuracy: 0.5679\n",
      "Epoch 00010: val_accuracy did not improve from 0.54584\n",
      "115101/115101 [==============================] - 46s 399us/sample - loss: 0.6779 - accuracy: 0.5678 - val_loss: 0.6952 - val_accuracy: 0.5413\n",
      "Epoch 11/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6764 - accuracy: 0.5714\n",
      "Epoch 00011: val_accuracy did not improve from 0.54584\n",
      "115101/115101 [==============================] - 44s 383us/sample - loss: 0.6765 - accuracy: 0.5713 - val_loss: 0.7073 - val_accuracy: 0.5177\n",
      ">>>>>>>>>>>>>>>>>>>> 1 LSTM layers with 32 units and 2 layer of DNN <<<<<<<<<<<<<<<<<<<<\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 60, 14)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                6016      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 8,417\n",
      "Trainable params: 8,289\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 115101 samples, validate on 28776 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6864 - accuracy: 0.5507\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50142, saving model to best_params_1_layer_32_units_2_dense\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_32_units_2_dense\\assets\n",
      "115101/115101 [==============================] - 60s 520us/sample - loss: 0.6864 - accuracy: 0.5506 - val_loss: 0.6988 - val_accuracy: 0.5014\n",
      "Epoch 2/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6824 - accuracy: 0.5606\n",
      "Epoch 00002: val_accuracy improved from 0.50142 to 0.51908, saving model to best_params_1_layer_32_units_2_dense\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_32_units_2_dense\\assets\n",
      "115101/115101 [==============================] - 57s 493us/sample - loss: 0.6824 - accuracy: 0.5606 - val_loss: 0.6985 - val_accuracy: 0.5191\n",
      "Epoch 3/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6812 - accuracy: 0.5636\n",
      "Epoch 00003: val_accuracy improved from 0.51908 to 0.55289, saving model to best_params_1_layer_32_units_2_dense\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_32_units_2_dense\\assets\n",
      "115101/115101 [==============================] - 58s 505us/sample - loss: 0.6812 - accuracy: 0.5635 - val_loss: 0.6927 - val_accuracy: 0.5529\n",
      "Epoch 4/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6800 - accuracy: 0.5668\n",
      "Epoch 00004: val_accuracy did not improve from 0.55289\n",
      "115101/115101 [==============================] - 45s 395us/sample - loss: 0.6800 - accuracy: 0.5669 - val_loss: 0.7015 - val_accuracy: 0.5231\n",
      "Epoch 5/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6790 - accuracy: 0.5681 ETA: 2s - loss: 0.6789 - \n",
      "Epoch 00005: val_accuracy did not improve from 0.55289\n",
      "115101/115101 [==============================] - 46s 401us/sample - loss: 0.6790 - accuracy: 0.5680 - val_loss: 0.6904 - val_accuracy: 0.5468\n",
      "Epoch 6/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6776 - accuracy: 0.5697\n",
      "Epoch 00006: val_accuracy did not improve from 0.55289\n",
      "115101/115101 [==============================] - 47s 411us/sample - loss: 0.6775 - accuracy: 0.5697 - val_loss: 0.6956 - val_accuracy: 0.5403\n",
      "Epoch 7/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6763 - accuracy: 0.5740\n",
      "Epoch 00007: val_accuracy did not improve from 0.55289\n",
      "115101/115101 [==============================] - 46s 402us/sample - loss: 0.6763 - accuracy: 0.5739 - val_loss: 0.6928 - val_accuracy: 0.5352\n",
      "Epoch 8/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6750 - accuracy: 0.5748\n",
      "Epoch 00008: val_accuracy did not improve from 0.55289\n",
      "115101/115101 [==============================] - 44s 384us/sample - loss: 0.6750 - accuracy: 0.5748 - val_loss: 0.7053 - val_accuracy: 0.5391\n",
      "Epoch 9/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6741 - accuracy: 0.5773 ETA: 0s - loss: 0.674\n",
      "Epoch 00009: val_accuracy did not improve from 0.55289\n",
      "115101/115101 [==============================] - 45s 391us/sample - loss: 0.6741 - accuracy: 0.5772 - val_loss: 0.7086 - val_accuracy: 0.5273\n",
      "Epoch 10/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6724 - accuracy: 0.5796\n",
      "Epoch 00010: val_accuracy did not improve from 0.55289\n",
      "115101/115101 [==============================] - 47s 412us/sample - loss: 0.6724 - accuracy: 0.5796 - val_loss: 0.7060 - val_accuracy: 0.5408\n",
      "Epoch 11/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6712 - accuracy: 0.5808\n",
      "Epoch 00011: val_accuracy did not improve from 0.55289\n",
      "115101/115101 [==============================] - 49s 424us/sample - loss: 0.6712 - accuracy: 0.5807 - val_loss: 0.7040 - val_accuracy: 0.5434\n",
      ">>>>>>>>>>>>>>>>>>>> 1 LSTM layers with 32 units and 3 layer of DNN <<<<<<<<<<<<<<<<<<<<\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 60, 14)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 32)                6016      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 9,601\n",
      "Trainable params: 9,409\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 115101 samples, validate on 28776 samples\n",
      "Epoch 1/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6897 - accuracy: 0.5424\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.54076, saving model to best_params_1_layer_32_units_3_dense\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_32_units_3_dense\\assets\n",
      "115101/115101 [==============================] - 60s 525us/sample - loss: 0.6897 - accuracy: 0.5424 - val_loss: 0.6879 - val_accuracy: 0.5408\n",
      "Epoch 2/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6844 - accuracy: 0.5556\n",
      "Epoch 00002: val_accuracy did not improve from 0.54076\n",
      "115101/115101 [==============================] - 43s 375us/sample - loss: 0.6844 - accuracy: 0.5557 - val_loss: 0.6945 - val_accuracy: 0.5375\n",
      "Epoch 3/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6820 - accuracy: 0.5607\n",
      "Epoch 00003: val_accuracy did not improve from 0.54076\n",
      "115101/115101 [==============================] - 44s 382us/sample - loss: 0.6820 - accuracy: 0.5607 - val_loss: 0.7013 - val_accuracy: 0.5390\n",
      "Epoch 4/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6796 - accuracy: 0.5666\n",
      "Epoch 00004: val_accuracy did not improve from 0.54076\n",
      "115101/115101 [==============================] - 46s 397us/sample - loss: 0.6796 - accuracy: 0.5667 - val_loss: 0.7706 - val_accuracy: 0.5084\n",
      "Epoch 5/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6774 - accuracy: 0.5700 ETA: 1s\n",
      "Epoch 00005: val_accuracy did not improve from 0.54076\n",
      "115101/115101 [==============================] - 47s 412us/sample - loss: 0.6774 - accuracy: 0.5699 - val_loss: 0.6995 - val_accuracy: 0.5383\n",
      "Epoch 6/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6748 - accuracy: 0.5757\n",
      "Epoch 00006: val_accuracy did not improve from 0.54076\n",
      "115101/115101 [==============================] - 49s 427us/sample - loss: 0.6747 - accuracy: 0.5758 - val_loss: 0.6961 - val_accuracy: 0.5369\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6722 - accuracy: 0.5812 ETA: 5s - loss: 0.6723 - accuracy - ETA: 5s - los - ETA: 1s - loss: 0.6721 - accuracy: 0.58 - ETA: 1s\n",
      "Epoch 00007: val_accuracy improved from 0.54076 to 0.54295, saving model to best_params_1_layer_32_units_3_dense\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_32_units_3_dense\\assets\n",
      "115101/115101 [==============================] - 59s 511us/sample - loss: 0.6722 - accuracy: 0.5812 - val_loss: 0.7473 - val_accuracy: 0.5430\n",
      "Epoch 8/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6702 - accuracy: 0.5841\n",
      "Epoch 00008: val_accuracy did not improve from 0.54295\n",
      "115101/115101 [==============================] - 45s 395us/sample - loss: 0.6702 - accuracy: 0.5841 - val_loss: 0.7310 - val_accuracy: 0.5269\n",
      "Epoch 9/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6678 - accuracy: 0.5896\n",
      "Epoch 00009: val_accuracy did not improve from 0.54295\n",
      "115101/115101 [==============================] - 47s 412us/sample - loss: 0.6679 - accuracy: 0.5895 - val_loss: 0.7494 - val_accuracy: 0.5427\n",
      "Epoch 10/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6652 - accuracy: 0.5929\n",
      "Epoch 00010: val_accuracy did not improve from 0.54295\n",
      "115101/115101 [==============================] - 49s 425us/sample - loss: 0.6652 - accuracy: 0.5928 - val_loss: 0.8195 - val_accuracy: 0.5115\n",
      "Epoch 11/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6632 - accuracy: 0.5979\n",
      "Epoch 00011: val_accuracy did not improve from 0.54295\n",
      "115101/115101 [==============================] - 48s 413us/sample - loss: 0.6632 - accuracy: 0.5979 - val_loss: 0.8133 - val_accuracy: 0.5425\n",
      "Epoch 12/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6612 - accuracy: 0.5995 ETA: 0s - loss: 0.6612 - accuracy\n",
      "Epoch 00012: val_accuracy did not improve from 0.54295\n",
      "115101/115101 [==============================] - 44s 386us/sample - loss: 0.6613 - accuracy: 0.5993 - val_loss: 0.9489 - val_accuracy: 0.5247\n",
      "Epoch 13/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6585 - accuracy: 0.6025\n",
      "Epoch 00013: val_accuracy did not improve from 0.54295\n",
      "115101/115101 [==============================] - 45s 389us/sample - loss: 0.6585 - accuracy: 0.6025 - val_loss: 0.8380 - val_accuracy: 0.5307\n",
      "Epoch 14/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6562 - accuracy: 0.6066\n",
      "Epoch 00014: val_accuracy did not improve from 0.54295\n",
      "115101/115101 [==============================] - 47s 408us/sample - loss: 0.6562 - accuracy: 0.6066 - val_loss: 0.8950 - val_accuracy: 0.5189\n",
      ">>>>>>>>>>>>>>>>>>>> 1 LSTM layers with 16 units and 0 layer of DNN <<<<<<<<<<<<<<<<<<<<\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 60, 14)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 16)                1984      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,001\n",
      "Trainable params: 2,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 115101 samples, validate on 28776 samples\n",
      "Epoch 1/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6879 - accuracy: 0.5397\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55001, saving model to best_params_1_layer_16_units_0_dense\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_16_units_0_dense\\assets\n",
      "115101/115101 [==============================] - 50s 435us/sample - loss: 0.6879 - accuracy: 0.5397 - val_loss: 0.6861 - val_accuracy: 0.5500\n",
      "Epoch 2/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6856 - accuracy: 0.5490\n",
      "Epoch 00002: val_accuracy improved from 0.55001 to 0.55887, saving model to best_params_1_layer_16_units_0_dense\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_16_units_0_dense\\assets\n",
      "115101/115101 [==============================] - 44s 386us/sample - loss: 0.6856 - accuracy: 0.5490 - val_loss: 0.6837 - val_accuracy: 0.5589\n",
      "Epoch 3/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6850 - accuracy: 0.5504\n",
      "Epoch 00003: val_accuracy did not improve from 0.55887\n",
      "115101/115101 [==============================] - 36s 312us/sample - loss: 0.6850 - accuracy: 0.5503 - val_loss: 0.6855 - val_accuracy: 0.5504\n",
      "Epoch 4/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6844 - accuracy: 0.5529 ETA: \n",
      "Epoch 00004: val_accuracy did not improve from 0.55887\n",
      "115101/115101 [==============================] - 38s 331us/sample - loss: 0.6843 - accuracy: 0.5529 - val_loss: 0.6860 - val_accuracy: 0.5522\n",
      "Epoch 5/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6839 - accuracy: 0.5534\n",
      "Epoch 00005: val_accuracy did not improve from 0.55887\n",
      "115101/115101 [==============================] - 40s 345us/sample - loss: 0.6839 - accuracy: 0.5534 - val_loss: 0.6888 - val_accuracy: 0.5416\n",
      "Epoch 6/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6837 - accuracy: 0.5560\n",
      "Epoch 00006: val_accuracy did not improve from 0.55887\n",
      "115101/115101 [==============================] - 41s 360us/sample - loss: 0.6837 - accuracy: 0.5560 - val_loss: 0.6838 - val_accuracy: 0.5569\n",
      "Epoch 7/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6833 - accuracy: 0.5561\n",
      "Epoch 00007: val_accuracy did not improve from 0.55887\n",
      "115101/115101 [==============================] - 40s 344us/sample - loss: 0.6833 - accuracy: 0.5561 - val_loss: 0.6861 - val_accuracy: 0.5503\n",
      "Epoch 8/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6832 - accuracy: 0.5565\n",
      "Epoch 00008: val_accuracy did not improve from 0.55887\n",
      "115101/115101 [==============================] - 39s 342us/sample - loss: 0.6831 - accuracy: 0.5566 - val_loss: 0.6856 - val_accuracy: 0.5521\n",
      "Epoch 9/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6828 - accuracy: 0.5582 ETA: 0s - loss: 0.6828 - accu\n",
      "Epoch 00009: val_accuracy did not improve from 0.55887\n",
      "115101/115101 [==============================] - 40s 349us/sample - loss: 0.6828 - accuracy: 0.5583 - val_loss: 0.6863 - val_accuracy: 0.5487\n",
      "Epoch 10/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6826 - accuracy: 0.5583\n",
      "Epoch 00010: val_accuracy did not improve from 0.55887\n",
      "115101/115101 [==============================] - 43s 373us/sample - loss: 0.6826 - accuracy: 0.5582 - val_loss: 0.6850 - val_accuracy: 0.5555\n",
      "Epoch 11/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6820 - accuracy: 0.5606\n",
      "Epoch 00011: val_accuracy did not improve from 0.55887\n",
      "115101/115101 [==============================] - 45s 395us/sample - loss: 0.6820 - accuracy: 0.5606 - val_loss: 0.6859 - val_accuracy: 0.5532\n",
      "Epoch 12/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6815 - accuracy: 0.5616\n",
      "Epoch 00012: val_accuracy did not improve from 0.55887\n",
      "115101/115101 [==============================] - 49s 423us/sample - loss: 0.6816 - accuracy: 0.5616 - val_loss: 0.6860 - val_accuracy: 0.5485\n",
      "Epoch 13/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6814 - accuracy: 0.5610\n",
      "Epoch 00013: val_accuracy did not improve from 0.55887\n",
      "115101/115101 [==============================] - 49s 430us/sample - loss: 0.6814 - accuracy: 0.5611 - val_loss: 0.6868 - val_accuracy: 0.5481\n",
      "Epoch 14/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6809 - accuracy: 0.5628\n",
      "Epoch 00014: val_accuracy did not improve from 0.55887\n",
      "115101/115101 [==============================] - 47s 412us/sample - loss: 0.6809 - accuracy: 0.5627 - val_loss: 0.6858 - val_accuracy: 0.5463\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6803 - accuracy: 0.5642\n",
      "Epoch 00015: val_accuracy did not improve from 0.55887\n",
      "115101/115101 [==============================] - 49s 424us/sample - loss: 0.6804 - accuracy: 0.5642 - val_loss: 0.6867 - val_accuracy: 0.5448\n",
      ">>>>>>>>>>>>>>>>>>>> 1 LSTM layers with 16 units and 1 layer of DNN <<<<<<<<<<<<<<<<<<<<\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 60, 14)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 16)                1984      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,337\n",
      "Trainable params: 2,305\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "Train on 115101 samples, validate on 28776 samples\n",
      "Epoch 1/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6884 - accuracy: 0.5454\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.51637, saving model to best_params_1_layer_16_units_1_dense\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_16_units_1_dense\\assets\n",
      "115101/115101 [==============================] - 67s 583us/sample - loss: 0.6884 - accuracy: 0.5454 - val_loss: 0.6983 - val_accuracy: 0.5164\n",
      "Epoch 2/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6853 - accuracy: 0.5530\n",
      "Epoch 00002: val_accuracy improved from 0.51637 to 0.53962, saving model to best_params_1_layer_16_units_1_dense\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_16_units_1_dense\\assets\n",
      "115101/115101 [==============================] - 59s 513us/sample - loss: 0.6853 - accuracy: 0.5531 - val_loss: 0.6915 - val_accuracy: 0.5396\n",
      "Epoch 3/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6838 - accuracy: 0.5568\n",
      "Epoch 00003: val_accuracy did not improve from 0.53962\n",
      "115101/115101 [==============================] - 51s 446us/sample - loss: 0.6838 - accuracy: 0.5569 - val_loss: 0.6924 - val_accuracy: 0.5340\n",
      "Epoch 4/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6831 - accuracy: 0.5564\n",
      "Epoch 00004: val_accuracy did not improve from 0.53962\n",
      "115101/115101 [==============================] - 56s 482us/sample - loss: 0.6831 - accuracy: 0.5565 - val_loss: 0.6908 - val_accuracy: 0.5342\n",
      "Epoch 5/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6827 - accuracy: 0.5597\n",
      "Epoch 00005: val_accuracy improved from 0.53962 to 0.54042, saving model to best_params_1_layer_16_units_1_dense\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_16_units_1_dense\\assets\n",
      "115101/115101 [==============================] - 67s 583us/sample - loss: 0.6827 - accuracy: 0.5597 - val_loss: 0.6901 - val_accuracy: 0.5404\n",
      "Epoch 6/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6821 - accuracy: 0.5610\n",
      "Epoch 00006: val_accuracy improved from 0.54042 to 0.54789, saving model to best_params_1_layer_16_units_1_dense\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_16_units_1_dense\\assets\n",
      "115101/115101 [==============================] - 67s 581us/sample - loss: 0.6821 - accuracy: 0.5609 - val_loss: 0.6881 - val_accuracy: 0.5479\n",
      "Epoch 7/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6816 - accuracy: 0.5599 ETA: 1s - loss: 0.6818 - accura - ETA: 1s - loss: 0.6817 \n",
      "Epoch 00007: val_accuracy did not improve from 0.54789\n",
      "115101/115101 [==============================] - 61s 534us/sample - loss: 0.6816 - accuracy: 0.5599 - val_loss: 0.6899 - val_accuracy: 0.5460\n",
      "Epoch 8/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6813 - accuracy: 0.5618\n",
      "Epoch 00008: val_accuracy did not improve from 0.54789\n",
      "115101/115101 [==============================] - 64s 556us/sample - loss: 0.6813 - accuracy: 0.5617 - val_loss: 0.6923 - val_accuracy: 0.5435\n",
      "Epoch 9/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6811 - accuracy: 0.5617\n",
      "Epoch 00009: val_accuracy improved from 0.54789 to 0.55539, saving model to best_params_1_layer_16_units_1_dense\n",
      "INFO:tensorflow:Assets written to: best_params_1_layer_16_units_1_dense\\assets\n",
      "115101/115101 [==============================] - 70s 606us/sample - loss: 0.6811 - accuracy: 0.5617 - val_loss: 0.6876 - val_accuracy: 0.5554\n",
      "Epoch 10/100\n",
      "114944/115101 [============================>.] - ETA: 0s - loss: 0.6807 - accuracy: 0.5637\n",
      "Epoch 00010: val_accuracy did not improve from 0.55539\n",
      "115101/115101 [==============================] - 65s 567us/sample - loss: 0.6807 - accuracy: 0.5637 - val_loss: 0.6950 - val_accuracy: 0.5266\n",
      "Epoch 11/100\n",
      " 97792/115101 [========================>.....] - ETA: 9s - loss: 0.6804 - accuracy: 0.5637"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', mode=\"min\", patience=10)\n",
    "\n",
    "K.clear_session()\n",
    "for n_layer_lstm in range(1,4):\n",
    "    for lstm_unit in [32, 16, 64]:\n",
    "        for n_layer_dense in [0, 1, 2, 3]:\n",
    "            print('>'*20,'{} LSTM layers with {} units and {} layer of DNN'.format(n_layer_lstm, lstm_unit, n_layer_dense), '<'*20)\n",
    "            model = get_model(n_layer_lstm = n_layer_lstm,\n",
    "                              lstm_unit = lstm_unit,\n",
    "                              n_layer_dense = n_layer_dense,\n",
    "                              dense_unit = lstm_unit,\n",
    "                              dense_dropout = 0.,\n",
    "                              lstm_dropout = 0.,\n",
    "                              act_fn = 'relu',\n",
    "                              lr=1e-3)\n",
    "            model.summary()\n",
    "            checkpoint = ModelCheckpoint(filepath='best_params_{}_layer_{}_units_{}_dense'.format(n_layer_lstm, lstm_unit, n_layer_dense), monitor=\"val_accuracy\",verbose = 1, save_best_only=True )\n",
    "            model.fit(X, y, validation_split=0.2, epochs=100, batch_size=256, callbacks=[checkpoint, early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
